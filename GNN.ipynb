{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1",
      "authorship_tag": "ABX9TyMsXsdM1kUdwcJyijGQhXpJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sudarshan-360/Machine-Learning/blob/main/GNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mBKuDheJU8U",
        "outputId": "58e4eb47-e158-4530-d6f9-5d5b139cd99b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cpu)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cpu)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cpu)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.8.0.html\n",
            "Collecting torch-geometric\n",
            "  Using cached torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "Collecting torch-scatter\n",
            "  Using cached torch_scatter-2.1.2.tar.gz (108 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "Requirement already satisfied: nilearn in /usr/local/lib/python3.12/dist-packages (0.12.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from nilearn) (1.5.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from nilearn) (6.0.1)\n",
            "Requirement already satisfied: nibabel>=5.2.0 in /usr/local/lib/python3.12/dist-packages (from nilearn) (5.3.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.12/dist-packages (from nilearn) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from nilearn) (25.0)\n",
            "Requirement already satisfied: pandas>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from nilearn) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.25.0 in /usr/local/lib/python3.12/dist-packages (from nilearn) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from nilearn) (1.16.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.12/dist-packages (from nibabel>=5.2.0->nilearn) (4.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.0->nilearn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.0->nilearn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.0->nilearn) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.25.0->nilearn) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.25.0->nilearn) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.25.0->nilearn) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.25.0->nilearn) (2025.8.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.2.0->nilearn) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision torchaudio\n",
        "!pip install torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-$(python3 -c \"import torch; print(torch.__version__.split('+')[0])\").html\n",
        "!pip install nilearn scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.8.0+cpu.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-2.8.0+cpu.html\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-2.8.0+cpu.html\n",
        "!pip install torch-spline-conv -f https://data.pyg.org/whl/torch-2.8.0+cpu.html\n",
        "!pip install torch-geometric\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nggAN4YLSQ-q",
        "outputId": "bd5ecd4d-c08c-40ef-b4de-7aa1f5e66339"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.8.0+cpu.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.8.0%2Bcpu/torch_scatter-2.1.2%2Bpt28cpu-cp312-cp312-linux_x86_64.whl (645 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m645.6/645.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2+pt28cpu\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.8.0+cpu.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.8.0%2Bcpu/torch_sparse-0.6.18%2Bpt28cpu-cp312-cp312-linux_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-sparse) (1.16.1)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy->torch-sparse) (2.0.2)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.18+pt28cpu\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.8.0+cpu.html\n",
            "Collecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.8.0%2Bcpu/torch_cluster-1.6.3%2Bpt28cpu-cp312-cp312-linux_x86_64.whl (749 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m749.6/749.6 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-cluster) (1.16.1)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy->torch-cluster) (2.0.2)\n",
            "Installing collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.3+pt28cpu\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.8.0+cpu.html\n",
            "Collecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.8.0%2Bcpu/torch_spline_conv-1.2.2%2Bpt28cpu-cp312-cp312-linux_x86_64.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.4/289.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.2.2+pt28cpu\n",
            "Collecting torch-geometric\n",
            "  Using cached torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "Collecting aiohttp (from torch-geometric)\n",
            "  Downloading aiohttp-3.12.15-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.9.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp->torch-geometric)\n",
            "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.4.0 (from aiohttp->torch-geometric)\n",
            "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp->torch-geometric)\n",
            "  Downloading frozenlist-1.7.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.6.4)\n",
            "Collecting propcache>=0.2.0 (from aiohttp->torch-geometric)\n",
            "  Downloading propcache-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp->torch-geometric)\n",
            "  Downloading yarl-1.20.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.9/73.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2025.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp-3.12.15-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
            "Downloading frozenlist-1.7.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.8/241.8 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading propcache-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.4/224.4 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yarl-1.20.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (355 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m355.6/355.6 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: propcache, frozenlist, aiohappyeyeballs, yarl, aiosignal, aiohttp, torch-geometric\n",
            "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 frozenlist-1.7.0 propcache-0.3.2 torch-geometric-2.6.1 yarl-1.20.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "from nilearn import datasets, input_data\n",
        "from torch_geometric.utils import dense_to_sparse\n",
        "\n",
        "# Check GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# 1. Fetch OASIS VBM dataset\n",
        "oasis = datasets.fetch_oasis_vbm(n_subjects=150)\n",
        "\n",
        "# 2. Fetch atlas (AAL)\n",
        "aal = datasets.fetch_atlas_aal() # This atlas divides the brain into 116 anatomical regions\n",
        "masker = input_data.NiftiLabelsMasker(labels_img=aal.maps, standardize=False) # Create a masker to extract region-wise features from MRI images\n",
        "masker.fit() #Learns the mapping of voxels → regions\n",
        "\n",
        "# 3. Extract region-wise features\n",
        "\n",
        "node_features_list = []\n",
        "for img_path in oasis.gray_matter_maps:\n",
        "    # Extract average gray matter values for each of the 116 brain regions\n",
        "    # Each region contains multiple voxels (3D pixels)\n",
        "\n",
        "    # masker.transform averages the voxel values in a region → 1 value per region\n",
        "    features = masker.transform(img_path).flatten() # flatten() converts the result into a 1D vector of size 116\n",
        "    node_features_list.append(features)\n",
        "\n",
        "print(\"Extracted features for\", len(node_features_list), \"subjects\")\n",
        "print(\"Each subject has\", node_features_list[0].shape[0], \"nodes\")\n",
        "\n",
        "# 4. Labels (CDR>=1 → positive)\n",
        "\n",
        "# if CDR >= 1 → 1 (dementia), else 0 (healthy)\n",
        "# CDR stands for Clinical Dementia Rating.\n",
        "labels = np.array([1 if cdr >= 1 else 0 for cdr in oasis.ext_vars['cdr']])\n",
        "print(\"Labels distribution:\", np.bincount(labels))\n",
        "\n",
        "# 5. Build PyG Data objects\n",
        "\n",
        "data_list = []\n",
        "for features, label in zip(node_features_list, labels):\n",
        "    x = torch.tensor(features[:, None], dtype=torch.float)  # each region is a node\n",
        "    n_nodes = x.shape[0]\n",
        "    diff = features[:, None] - features[None, :]\n",
        "    edge_weight_matrix = np.exp(-np.abs(diff)) #Converts Diff -> Similarity: Small difference → similarity ≈ 1, Large difference → similarity → closer to 0\n",
        "    dense = torch.tensor(edge_weight_matrix, dtype=torch.float)\n",
        "    # make sparse graph (needed for GCN) -  Adjacency matrix\n",
        "    edge_index, edge_weight = dense_to_sparse(dense)\n",
        "    y = torch.tensor([label], dtype=torch.long)\n",
        "    data_list.append(Data(x=x, edge_index=edge_index, edge_weight=edge_weight, y=y))\n",
        "\n",
        "print(\"Graphs built:\", len(data_list))\n",
        "\n",
        "# 6. Define GCN model\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self, in_dim=1, hidden=64, dropout=0.5):\n",
        "        super().__init__()\n",
        "        # First GCN layer: converts input node features to 'hidden' dimension\n",
        "        self.conv1 = GCNConv(in_dim, hidden)\n",
        "        # Second GCN layer: keeps hidden dimension same, learns more graph patterns\n",
        "        self.conv2 = GCNConv(hidden, hidden)\n",
        "        # Fully connected layer to output 2 classes (CDR<1 or CDR>=1)\n",
        "        self.lin   = nn.Linear(hidden, 2)\n",
        "        # Dropout probability to prevent overfitting\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, x, edge_index, batch, edge_weight=None):\n",
        "        x = F.relu(self.conv1(x, edge_index, edge_weight=edge_weight))\n",
        "        #Regularisation to avoid overfitting\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = F.relu(self.conv2(x, edge_index, edge_weight=edge_weight))\n",
        "        # Pool node features into a single graph feature vector (mean of all nodes)\n",
        "        x = global_mean_pool(x, batch)\n",
        "        return self.lin(x)\n",
        "\n",
        "# 7. Training loop function\n",
        "def run_one_epoch(model, loader, optimizer=None, class_weights=None):\n",
        "    is_train = optimizer is not None\n",
        "    model.train() if is_train else model.eval()\n",
        "    all_preds, all_probs, all_labels = [], [], []\n",
        "    total_loss = 0.0\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_weights.to(device) if class_weights is not None else None)\n",
        "\n",
        "    for batch in loader:\n",
        "        batch = batch.to(device)\n",
        "        logits = model(batch.x, batch.edge_index, batch.batch, edge_weight=batch.edge_weight)\n",
        "        loss = criterion(logits, batch.y.view(-1))\n",
        "\n",
        "        if is_train:\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        total_loss += float(loss.item()) * batch.num_graphs\n",
        "\n",
        "        with torch.no_grad():\n",
        "            probs = F.softmax(logits, dim=1)[:, 1].cpu().numpy()\n",
        "            preds = logits.argmax(dim=1).cpu().numpy()\n",
        "            labels_batch = batch.y.view(-1).cpu().numpy()\n",
        "            all_probs.extend(probs.tolist())\n",
        "            all_preds.extend(preds.tolist())\n",
        "            all_labels.extend(labels_batch.tolist())\n",
        "\n",
        "    avg_loss = total_loss / len(loader.dataset)\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    try:\n",
        "        auc = roc_auc_score(all_labels, all_probs)\n",
        "    except ValueError:\n",
        "        auc = float('nan')\n",
        "    return avg_loss, acc, auc\n",
        "\n",
        "# 8. Class weights\n",
        "\n",
        "# Convert labels to numpy array for calculation\n",
        "labels_np = np.array(labels)\n",
        "\n",
        "# Count how many positive (CDR>=1) and negative (CDR<1) samples\n",
        "pos, neg = (labels_np == 1).sum(), (labels_np == 0).sum()\n",
        "\n",
        "# Calculate class weights to balance training:\n",
        "# If there are fewer negatives, give them more weight and vice versa\n",
        "\n",
        "w0 = 1.0 if neg == 0 else (pos + neg) / (2.0 * neg)\n",
        "w1 = 1.0 if pos == 0 else (pos + neg) / (2.0 * pos)\n",
        "class_weights = torch.tensor([w0, w1], dtype=torch.float)\n",
        "print(f\"Class balance -> neg: {neg}, pos: {pos}, weights: {w0:.2f}, {w1:.2f}\")\n",
        "\n",
        "# 9. Cross-validation\n",
        "def cross_validate_k(data_list, labels_np, k, epochs=200, patience=20):\n",
        "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
        "    fold_metrics = []\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(skf.split(np.arange(len(labels_np)), labels_np), start=1):\n",
        "        train_list = [data_list[i] for i in train_idx]\n",
        "        val_list   = [data_list[i] for i in val_idx]\n",
        "\n",
        "        train_loader = DataLoader(train_list, batch_size=8, shuffle=True)\n",
        "        val_loader   = DataLoader(val_list, batch_size=8, shuffle=False)\n",
        "\n",
        "        in_dim = data_list[0].x.shape[1]\n",
        "        model = GCN(in_dim=in_dim, hidden=64, dropout=0.5).to(device)\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=5e-4, weight_decay=1e-4)\n",
        "\n",
        "        best_val_auc, patience_cnt = -1.0, 0\n",
        "        for epoch in range(1, epochs + 1):\n",
        "            tr_loss, tr_acc, tr_auc = run_one_epoch(model, train_loader, optimizer, class_weights)\n",
        "            val_loss, val_acc, val_auc = run_one_epoch(model, val_loader, optimizer=None, class_weights=class_weights)\n",
        "\n",
        "            if val_auc > best_val_auc:\n",
        "                best_val_auc = val_auc\n",
        "                patience_cnt = 0\n",
        "                best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
        "            else:\n",
        "                patience_cnt += 1\n",
        "            if patience_cnt >= patience:\n",
        "                break\n",
        "\n",
        "        model.load_state_dict({k: v.to(device) for k, v in best_state.items()})\n",
        "        val_loss, val_acc, val_auc = run_one_epoch(model, val_loader, optimizer=None, class_weights=class_weights)\n",
        "        fold_metrics.append((val_acc, val_auc))\n",
        "\n",
        "    accs = [m[0] for m in fold_metrics]\n",
        "    aucs = [m[1] for m in fold_metrics]\n",
        "    return np.nanmean(accs), np.nanstd(accs), np.nanmean(aucs), np.nanstd(aucs)\n",
        "\n",
        "# 10. Evaluate with different k\n",
        "candidate_ks = [2, 3, 5]\n",
        "for k in candidate_ks:\n",
        "    mean_acc, std_acc, mean_auc, std_auc = cross_validate_k(data_list, labels_np, k)\n",
        "    print(f\"k={k} -> ACC {mean_acc:.3f} ± {std_acc:.3f}, AUC {mean_auc:.3f} ± {std_auc:.3f}\")\n"
      ],
      "metadata": {
        "id": "EGQbsj2LJZ-T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d27132ba-1dc3-4925-f0d4-49c1e87a65bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1150597553.py:9: DeprecationWarning: The import path 'nilearn.input_data' is deprecated in version 0.9. Importing from 'nilearn.input_data' will be possible at least until release 0.13.0. Please import from 'nilearn.maskers' instead.\n",
            "  from nilearn import datasets, input_data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;34m[\u001b[0m\u001b[34mfetch_oasis_vbm\u001b[0m\u001b[1;34m]\u001b[0m Added README.md to \u001b[35m/root/\u001b[0m\u001b[95mnilearn_data\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_oasis_vbm</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Added README.md to <span style=\"color: #800080; text-decoration-color: #800080\">/root/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">nilearn_data</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;34m[\u001b[0m\u001b[34mfetch_oasis_vbm\u001b[0m\u001b[1;34m]\u001b[0m Dataset created in \u001b[35m/root/nilearn_data/\u001b[0m\u001b[95moasis1\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_oasis_vbm</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Dataset created in <span style=\"color: #800080; text-decoration-color: #800080\">/root/nilearn_data/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">oasis1</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;34m[\u001b[0m\u001b[34mfetch_oasis_vbm\u001b[0m\u001b[1;34m]\u001b[0m Downloading data from \u001b[4;94mhttps://www.nitrc.org/frs/download.php/6364/archive_dartel.tgz\u001b[0m \u001b[33m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_oasis_vbm</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Downloading data from <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://www.nitrc.org/frs/download.php/6364/archive_dartel.tgz</span> <span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;34m[\u001b[0m\u001b[34mfetch_oasis_vbm\u001b[0m\u001b[1;34m]\u001b[0m Downloaded \u001b[1;36m25133056\u001b[0m of \u001b[1;36m905208634\u001b[0m bytes \u001b[1m(\u001b[0m\u001b[1;36m2.8\u001b[0m%%,   \u001b[1;36m36.\u001b[0m8s remaining\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_oasis_vbm</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Downloaded <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25133056</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">905208634</span> bytes <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.8</span>%%,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36.</span>8s remaining<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;34m[\u001b[0m\u001b[34mfetch_oasis_vbm\u001b[0m\u001b[1;34m]\u001b[0m Downloaded \u001b[1;36m72245248\u001b[0m of \u001b[1;36m905208634\u001b[0m bytes \u001b[1m(\u001b[0m\u001b[1;36m8.0\u001b[0m%%,   \u001b[1;36m23.\u001b[0m8s remaining\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_oasis_vbm</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Downloaded <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">72245248</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">905208634</span> bytes <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.0</span>%%,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23.</span>8s remaining<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;34m[\u001b[0m\u001b[34mfetch_oasis_vbm\u001b[0m\u001b[1;34m]\u001b[0m Downloaded \u001b[1;36m121593856\u001b[0m of \u001b[1;36m905208634\u001b[0m bytes \u001b[1m(\u001b[0m\u001b[1;36m13.4\u001b[0m%%,   \u001b[1;36m19.\u001b[0m8s remaining\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_oasis_vbm</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Downloaded <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">121593856</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">905208634</span> bytes <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13.4</span>%%,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19.</span>8s remaining<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;34m[\u001b[0m\u001b[34mfetch_oasis_vbm\u001b[0m\u001b[1;34m]\u001b[0m Downloaded \u001b[1;36m167690240\u001b[0m of \u001b[1;36m905208634\u001b[0m bytes \u001b[1m(\u001b[0m\u001b[1;36m18.5\u001b[0m%%,   \u001b[1;36m18.\u001b[0m0s remaining\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_oasis_vbm</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Downloaded <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">167690240</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">905208634</span> bytes <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18.5</span>%%,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18.</span>0s remaining<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;34m[\u001b[0m\u001b[34mfetch_oasis_vbm\u001b[0m\u001b[1;34m]\u001b[0m Downloaded \u001b[1;36m218079232\u001b[0m of \u001b[1;36m905208634\u001b[0m bytes \u001b[1m(\u001b[0m\u001b[1;36m24.1\u001b[0m%%,   \u001b[1;36m16.\u001b[0m1s remaining\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_oasis_vbm</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Downloaded <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">218079232</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">905208634</span> bytes <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24.1</span>%%,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16.</span>1s remaining<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;34m[\u001b[0m\u001b[34mfetch_oasis_vbm\u001b[0m\u001b[1;34m]\u001b[0m Downloaded \u001b[1;36m266977280\u001b[0m of \u001b[1;36m905208634\u001b[0m bytes \u001b[1m(\u001b[0m\u001b[1;36m29.5\u001b[0m%%,   \u001b[1;36m14.\u001b[0m7s remaining\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_oasis_vbm</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Downloaded <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">266977280</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">905208634</span> bytes <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">29.5</span>%%,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14.</span>7s remaining<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;34m[\u001b[0m\u001b[34mfetch_oasis_vbm\u001b[0m\u001b[1;34m]\u001b[0m Downloaded \u001b[1;36m315129856\u001b[0m of \u001b[1;36m905208634\u001b[0m bytes \u001b[1m(\u001b[0m\u001b[1;36m34.8\u001b[0m%%,   \u001b[1;36m13.\u001b[0m4s remaining\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_oasis_vbm</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Downloaded <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">315129856</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">905208634</span> bytes <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">34.8</span>%%,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13.</span>4s remaining<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;34m[\u001b[0m\u001b[34mfetch_oasis_vbm\u001b[0m\u001b[1;34m]\u001b[0m Downloaded \u001b[1;36m365805568\u001b[0m of \u001b[1;36m905208634\u001b[0m bytes \u001b[1m(\u001b[0m\u001b[1;36m40.4\u001b[0m%%,   \u001b[1;36m12.\u001b[0m1s remaining\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_oasis_vbm</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Downloaded <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">365805568</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">905208634</span> bytes <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40.4</span>%%,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12.</span>1s remaining<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;34m[\u001b[0m\u001b[34mfetch_oasis_vbm\u001b[0m\u001b[1;34m]\u001b[0m Downloaded \u001b[1;36m415105024\u001b[0m of \u001b[1;36m905208634\u001b[0m bytes \u001b[1m(\u001b[0m\u001b[1;36m45.9\u001b[0m%%,   \u001b[1;36m10.\u001b[0m9s remaining\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_oasis_vbm</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Downloaded <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">415105024</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">905208634</span> bytes <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">45.9</span>%%,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10.</span>9s remaining<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;34m[\u001b[0m\u001b[34mfetch_oasis_vbm\u001b[0m\u001b[1;34m]\u001b[0m Downloaded \u001b[1;36m464576512\u001b[0m of \u001b[1;36m905208634\u001b[0m bytes \u001b[1m(\u001b[0m\u001b[1;36m51.3\u001b[0m%%,    \u001b[1;36m9.\u001b[0m7s remaining\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_oasis_vbm</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Downloaded <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">464576512</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">905208634</span> bytes <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">51.3</span>%%,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.</span>7s remaining<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;34m[\u001b[0m\u001b[34mfetch_oasis_vbm\u001b[0m\u001b[1;34m]\u001b[0m Downloaded \u001b[1;36m510648320\u001b[0m of \u001b[1;36m905208634\u001b[0m bytes \u001b[1m(\u001b[0m\u001b[1;36m56.4\u001b[0m%%,    \u001b[1;36m8.\u001b[0m7s remaining\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_oasis_vbm</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Downloaded <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">510648320</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">905208634</span> bytes <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">56.4</span>%%,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.</span>7s remaining<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;34m[\u001b[0m\u001b[34mfetch_oasis_vbm\u001b[0m\u001b[1;34m]\u001b[0m Downloaded \u001b[1;36m561405952\u001b[0m of \u001b[1;36m905208634\u001b[0m bytes \u001b[1m(\u001b[0m\u001b[1;36m62.0\u001b[0m%%,    \u001b[1;36m7.\u001b[0m5s remaining\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_oasis_vbm</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Downloaded <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">561405952</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">905208634</span> bytes <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">62.0</span>%%,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7.</span>5s remaining<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;34m[\u001b[0m\u001b[34mfetch_oasis_vbm\u001b[0m\u001b[1;34m]\u001b[0m Downloaded \u001b[1;36m610533376\u001b[0m of \u001b[1;36m905208634\u001b[0m bytes \u001b[1m(\u001b[0m\u001b[1;36m67.4\u001b[0m%%,    \u001b[1;36m6.\u001b[0m4s remaining\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_oasis_vbm</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Downloaded <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">610533376</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">905208634</span> bytes <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">67.4</span>%%,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6.</span>4s remaining<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;34m[\u001b[0m\u001b[34mfetch_oasis_vbm\u001b[0m\u001b[1;34m]\u001b[0m Downloaded \u001b[1;36m661987328\u001b[0m of \u001b[1;36m905208634\u001b[0m bytes \u001b[1m(\u001b[0m\u001b[1;36m73.1\u001b[0m%%,    \u001b[1;36m5.\u001b[0m2s remaining\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_oasis_vbm</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Downloaded <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">661987328</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">905208634</span> bytes <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">73.1</span>%%,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.</span>2s remaining<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;34m[\u001b[0m\u001b[34mfetch_oasis_vbm\u001b[0m\u001b[1;34m]\u001b[0m Downloaded \u001b[1;36m713228288\u001b[0m of \u001b[1;36m905208634\u001b[0m bytes \u001b[1m(\u001b[0m\u001b[1;36m78.8\u001b[0m%%,    \u001b[1;36m4.\u001b[0m1s remaining\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_oasis_vbm</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Downloaded <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">713228288</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">905208634</span> bytes <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">78.8</span>%%,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.</span>1s remaining<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;34m[\u001b[0m\u001b[34mfetch_oasis_vbm\u001b[0m\u001b[1;34m]\u001b[0m Downloaded \u001b[1;36m763371520\u001b[0m of \u001b[1;36m905208634\u001b[0m bytes \u001b[1m(\u001b[0m\u001b[1;36m84.3\u001b[0m%%,    \u001b[1;36m3.\u001b[0m0s remaining\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_oasis_vbm</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Downloaded <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">763371520</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">905208634</span> bytes <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">84.3</span>%%,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.</span>0s remaining<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;34m[\u001b[0m\u001b[34mfetch_oasis_vbm\u001b[0m\u001b[1;34m]\u001b[0m Downloaded \u001b[1;36m813547520\u001b[0m of \u001b[1;36m905208634\u001b[0m bytes \u001b[1m(\u001b[0m\u001b[1;36m89.9\u001b[0m%%,    \u001b[1;36m2.\u001b[0m0s remaining\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_oasis_vbm</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Downloaded <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">813547520</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">905208634</span> bytes <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">89.9</span>%%,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.</span>0s remaining<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;34m[\u001b[0m\u001b[34mfetch_oasis_vbm\u001b[0m\u001b[1;34m]\u001b[0m Downloaded \u001b[1;36m861978624\u001b[0m of \u001b[1;36m905208634\u001b[0m bytes \u001b[1m(\u001b[0m\u001b[1;36m95.2\u001b[0m%%,    \u001b[1;36m0.\u001b[0m9s remaining\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_oasis_vbm</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Downloaded <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">861978624</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">905208634</span> bytes <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">95.2</span>%%,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.</span>9s remaining<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;34m[\u001b[0m\u001b[34mfetch_oasis_vbm\u001b[0m\u001b[1;34m]\u001b[0m  \u001b[33m...\u001b[0mdone. \u001b[1m(\u001b[0m\u001b[1;36m20\u001b[0m seconds, \u001b[1;36m0\u001b[0m min\u001b[1m)\u001b[0m\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_oasis_vbm</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span>  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>done. <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> seconds, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> min<span style=\"font-weight: bold\">)</span>\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;34m[\u001b[0m\u001b[34mfetch_oasis_vbm\u001b[0m\u001b[1;34m]\u001b[0m Extracting data from \n",
              "\u001b[35m/root/nilearn_data/oasis1/1f9e951d7636496ace13e77a1ffb1751/\u001b[0m\u001b[95marchive_dartel.tgz...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_oasis_vbm</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Extracting data from \n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">/root/nilearn_data/oasis1/1f9e951d7636496ace13e77a1ffb1751/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">archive_dartel.tgz...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;34m[\u001b[0m\u001b[34mfetch_oasis_vbm\u001b[0m\u001b[1;34m]\u001b[0m .. done.\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_oasis_vbm</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> .. done.\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1150597553.py:20: DeprecationWarning: Starting in version 0.13, the default fetched mask will beAAL 3v2 instead.\n",
            "  aal = datasets.fetch_atlas_aal()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;34m[\u001b[0m\u001b[34mfetch_atlas_aal\u001b[0m\u001b[1;34m]\u001b[0m Dataset created in \u001b[35m/root/nilearn_data/\u001b[0m\u001b[95maal_SPM12\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_atlas_aal</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Dataset created in <span style=\"color: #800080; text-decoration-color: #800080\">/root/nilearn_data/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">aal_SPM12</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;34m[\u001b[0m\u001b[34mfetch_atlas_aal\u001b[0m\u001b[1;34m]\u001b[0m Downloading data from \u001b[4;94mhttps://www.gin.cnrs.fr/AAL_files/aal_for_SPM12.tar.gz\u001b[0m \u001b[33m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_atlas_aal</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Downloading data from <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://www.gin.cnrs.fr/AAL_files/aal_for_SPM12.tar.gz</span> <span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;34m[\u001b[0m\u001b[34mfetch_atlas_aal\u001b[0m\u001b[1;34m]\u001b[0m  \u001b[33m...\u001b[0mdone. \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m seconds, \u001b[1;36m0\u001b[0m min\u001b[1m)\u001b[0m\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_atlas_aal</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span>  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>done. <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> seconds, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> min<span style=\"font-weight: bold\">)</span>\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;34m[\u001b[0m\u001b[34mfetch_atlas_aal\u001b[0m\u001b[1;34m]\u001b[0m Extracting data from \n",
              "\u001b[35m/root/nilearn_data/aal_SPM12/5d72fe1c9daf02b658cbf1f7e7026e0f/\u001b[0m\u001b[95maal_for_SPM12.tar.gz...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_atlas_aal</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Extracting data from \n",
              "<span style=\"color: #800080; text-decoration-color: #800080\">/root/nilearn_data/aal_SPM12/5d72fe1c9daf02b658cbf1f7e7026e0f/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">aal_for_SPM12.tar.gz...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;34m[\u001b[0m\u001b[34mfetch_atlas_aal\u001b[0m\u001b[1;34m]\u001b[0m .. done.\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_atlas_aal</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> .. done.\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted features for 150 subjects\n",
            "Each subject has 116 nodes\n",
            "Labels distribution: [140  10]\n",
            "Graphs built: 150\n",
            "Class balance -> neg: 140, pos: 10, weights: 0.54, 7.50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n",
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k=2 -> ACC 0.500 ± 0.433, AUC 0.667 ± 0.033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n",
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n",
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k=3 -> ACC 0.640 ± 0.410, AUC 0.514 ± 0.172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n",
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n",
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n",
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n",
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k=5 -> ACC 0.760 ± 0.347, AUC 0.525 ± 0.222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mk4T1hdBTXSX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}